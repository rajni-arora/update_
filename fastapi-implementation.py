ðŸ”Ž Why knowledge_recall is needed

When you rewrite a userâ€™s query (with LLM), you donâ€™t want the model to work blindly.
You want it to see relevant knowledge and examples from your system so that the rewrite is:
	â€¢	Accurate (uses the right domain/business context)
	â€¢	Grounded (not hallucinated)
	â€¢	Consistent (uses the same examples/terminology as the KB)

Thatâ€™s exactly what knowledge_recall is doing: it prepares the evidence/context for the LLM before you inject it into the prompt.

â¸»

ðŸŽ¯ Goals of knowledge_recall
	1.	Bring in relevant knowledge
	â€¢	From semantic search (captures meaning similarity)
	â€¢	From TF-IDF keyword search (captures exact keyword matches)
	â€¢	This hybrid recall improves recall (coverage) and precision (relevance).
	2.	Deduplicate & Clean
	â€¢	Avoid redundant knowledge snippets.
	â€¢	Normalize whitespace and text so comparison is consistent.
	3.	Prepare Few-Shot Examples
	â€¢	Dynamically fetch examples tied to the recalled knowledge.
	â€¢	These are injected as few-shot prompts, helping the LLM learn how to rewrite queries correctly.
	4.	Output in Model-Readable Format
	â€¢	Stitch the results into two neat strings:
	â€¢	kg_repr: the recalled domain knowledge.
	â€¢	dynamic_examples_repr: related examples.

These strings then slot directly into the prompt template in get_qr_prompt.

â¸»

ðŸ”— Where it fits

ðŸ‘‰ User query â†’ knowledge_recall â†’ get_qr_prompt â†’ invoke_query_llm â†’ rewritten query

So without knowledge_recall, your LLM would only see the raw query, without context or examples.
That would lead to weak, less accurate, and less controlled rewrites.
